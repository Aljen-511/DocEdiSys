import os
import sys
cur_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(cur_dir, "gRPC"))
from patch import get_patch, apply_patch_cover
import redis
from gRPC import DisServ_pb2
from gRPC import DisServ_pb2_grpc
from gRPC.atomScript import LuaScript
import grpc

import yaml
from concurrent import futures
import threading
import time

# 1. æ‰€æœ‰messageç±»çš„å®šä¹‰åœ¨DisDerv_pb2ä¸­, å½“è¦è¿”å›æŒ‡å®šä¿¡æ¯æ—¶ï¼Œå¯ä»¥æ ¹æ®è¿™äº›ç±»åˆå§‹åŒ–æŒ‡å®šå¯¹è±¡
# 2. ç»§æ‰¿äº†servicerç±»ä¹‹å, éœ€è¦å®Œæˆserviceä¸­å®šä¹‰çš„å®ç°
# 3. æ¶ˆæ¯çš„è§£ææ–¹æ³•å‚ç…§DisDerv_pb2


'''
åˆå§‹åŒ–ä¿¡æ¯ç±»ç¤ºä¾‹:
item = DisServ_pb2.single_patch_item(op = xxx, start_line = xxx, cont_line = xxx, cont = xxx)
è®¿é—®ä¿¡æ¯ç±»æˆå‘˜ç¤ºä¾‹:
item.op
item.cont_line
etc...
'''


class server(DisServ_pb2_grpc.DisServServicer):
    def __init__(self):
        # åˆå§‹åŒ–æœåŠ¡å™¨
        super(server, self).__init__()
        # é…ç½®æ–‡ä»¶é»˜è®¤åœ¨srcçš„cfgç›®å½•ä¸‹
        self.server_conf_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),"cfg/serCfg.yaml")
        with open(self.server_conf_path, 'r', encoding='utf-8') as f:
            cfg = yaml.load(f.read(), Loader=yaml.FullLoader)
        self.redisCli = redis.Redis(host=cfg["redis"]["host"],port=cfg["redis"]["port"],db=cfg["redis"]["db"])

        # å…±äº«æ–‡æ¡£çš„è·¯å¾„
        self.share_path = cfg["share_path"]

        # æ¯ä¸ªæ–‡æ¡£å…è®¸åœ¨å†…å­˜ä¸­å®æ—¶å­˜å‚¨çš„è¡¥ä¸æ•°é‡ä¸‹é™(k)
        self.k = cfg["num_patches"]

        # æ–‡æ¡£ç‰ˆæœ¬ä¸æœ€æ–°è¡¥ä¸ç›¸å·®è¶…è¿‡è¯¥é˜ˆå€¼, æ‰ä¼šå†™å…¥ä¿®æ”¹
        self.threshold = cfg["threshold"]

        # è§„å®šæœåŠ¡å™¨çš„ç›‘å¬ç«¯å£
        self.serPort = cfg["listen_port"]

        # åˆå§‹åŒ–Luaè„šæœ¬
        self.initial_scripts()

        # ç¡®ä¿ç”¨æˆ·IDåˆ†é…æ“ä½œçš„åŸå­æ€§
        self.ID_Info_mtx = threading.Lock()

        # ç¡®ä¿æ–‡ä»¶æ‰¹é‡å†™å…¥è¡¥ä¸æ“ä½œå’Œè¯·æ±‚æ–‡ä»¶æ“ä½œçš„äº’æ–¥
        self.doc_mtx = threading.Lock()

        # è¿›è¡Œå¿…è¦çš„redisåˆå§‹åŒ–
        self.check_database()

        maintain_th = threading.Thread(target=self.maintain_th)
        maintain_th.start()

    def initial_scripts(self)-> None:
        '''
        åˆå§‹åŒ–å¹¶æ³¨å†ŒLuaè„šæœ¬
        '''
        scripts = LuaScript()
        self.update_patch = self.redisCli.register_script(scripts.update_patch)
        self.init_share_doc = self.redisCli.register_script(scripts.init_share_doc)
        self.recall_doc = self.redisCli.register_script(scripts.recall_doc)


    def check_database(self)-> None:
        '''
        æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å­˜åœ¨é¢„è®¾çš„é”®, è‹¥æ²¡æœ‰åˆ™è¿›è¡Œåˆ›å»º, å¹¶åˆå§‹åŒ–
        '''
        # å¯¹10Wé‡çº§ä»¥ä¸‹çš„ç”¨æˆ·é‡, å•å°æœåŠ¡å™¨çš„å†…å­˜é‡è¶³ä»¥æ”¯æ’‘ä»¥ä¸‹Redisé”®å€¼å¯¹çš„è¿ä½œ
        # ç”¨æˆ·æœ€å¤§IDå€¼--> max_usr_ID:: int
        # ç”¨æˆ·åˆ—è¡¨--> usrlst(rediså“ˆå¸Œè¡¨ç±»å‹):: usr_ID:usr_name(str) 
        # ç”¨æˆ·åœ¨çº¿åˆ—è¡¨--> online_usr(redisé›†åˆç±»å‹):: usr_ID(int64) #æ²¡æœ‰å¿…è¦ç»´æŠ¤åœ¨çº¿çŠ¶æ€
        # å…±äº«æ–‡æ¡£åˆ—è¡¨--> share_doc(rediså“ˆå¸Œè¡¨ç±»å‹):: document_info(åºåˆ—åŒ–):timestamp(int64)
        # æ–‡æ¡£patchåˆ—è¡¨ç´¢å¼•--> doc_patch(rediså“ˆå¸Œè¡¨ç±»å‹):: document_info(åºåˆ—åŒ–):patchlistid
        # æ–‡æ¡£patchåˆ—è¡¨--> patchlistid(redisåˆ—è¡¨ç±»å‹):: patch(åºåˆ—åŒ–)
        # æœ¬åœ°æ–‡æ¡£å‰¯æœ¬æ—¶é—´æˆ³--> dup_doc_ver(rediså“ˆå¸Œè¡¨ç±»å‹):: document_info(åºåˆ—åŒ–):timestamp(int64)
        # æœ€å¤§patchåˆ—è¡¨IDå€¼--> max_patch_list_ID:: int
        if not self.redisCli.exists("max_usr_ID"):
            self.redisCli.set("max_usr_ID", 0)
        if not self.redisCli.exists("usrlst"):
            self.redisCli.hset("usrlst"," "," ")
        if not self.redisCli.exists("share_doc"):
            self.redisCli.hset("share_doc", " ", " ")
        if not self.redisCli.exists("doc_patch"):
            self.redisCli.hset("doc_patch", " ", " ")
        if not self.redisCli.exists("dup_doc_ver"):
            self.redisCli.hset("dup_doc_ver", " ", " ")
        if not self.redisCli.exists("max_patch_list_ID"):
            self.redisCli.set("max_patch_list_ID",0)
        

        
        
    def upload_patch(self, request, context):
        '''
        request: patchç±»å‹ä¿¡æ¯,åŒ…å« <æ—¶é—´æˆ³time_stamp, ç”³è¯·å®¢æˆ·ä¿¡æ¯appli_usr, ç”³è¯·ä¿®æ”¹æ–‡æ¡£ä¿¡æ¯appli_doc, patchåˆ—è¡¨items>
        response: boolen_resç±»å‹ä¿¡æ¯, è±¡å¾æ€§å›å¤
        '''
        # 0. é¦–å…ˆæ£€æŸ¥å¯¹åº”çš„æ–‡æ¡£æ˜¯å¦å­˜åœ¨, è‹¥ä¸å­˜åœ¨è¿”å›false, æš—ç¤ºè¯¥æ–‡æ¡£å·²è¢«ç§»é™¤
        # 1. æŸ¥è¯¢å¯¹åº”çš„patchæ—¶é—´æˆ³, åŒ¹é…åˆ™è¿›å…¥ä¸‹ä¸€æ­¥, å¦åˆ™ç›´æ¥æ‹’ç»
        # 2. æˆåŠŸå†™å…¥, åˆ™å°†è¯¥ä¿®æ”¹è¿›è¡Œå¹¿æ’­(åœ¨åç»­å®¢æˆ·ç«¯æ¯éš”ä¸€æ®µæ—¶é—´çš„è½®è¯¢ä¸­è¿›è¡Œ)
        # * è¦ç¡®ä¿å†™å…¥æ“ä½œæ˜¯åŸå­çš„
        
        req_doc_info_serial = request.appli_doc.SerializeToString()
        
        
        if not self.redisCli.hexists("share_doc", req_doc_info_serial):
            return DisServ_pb2.boolen_res(accept_status = False)
        else:
            patch_serial = request.SerializeToString()
            time_stamp = request.time_stamp
            patch_Lst_ID = self.redisCli.hget("doc_patch", req_doc_info_serial)
            #-------åŸå­æ“ä½œåŒº-------#
            # ä¼ å…¥share_docé”®, ä¼ å…¥æ–‡æ¡£çš„info(åºåˆ—åŒ–), ä¼ å…¥å½“å‰patchæ—¶é—´æˆ³; 
            # ä¼ å…¥patch_Lst_IDé”®, ä¼ å…¥å½“å‰patch(åºåˆ—åŒ–)
            # 
            keys = ["share_doc", patch_Lst_ID]
            args = [req_doc_info_serial, time_stamp, patch_serial]
            self.update_patch(keys=keys, args=args)
            #------------------------#

            # æ— éœ€å…³å¿ƒæ˜¯å¦æˆåŠŸå†™å…¥, å› ä¸ºæœåŠ¡å™¨æ€»æ˜¯ä¼šå‘å¸ƒæœ€æ–°çš„ä¸€è‡´è¡¥ä¸
            return DisServ_pb2.boolen_res(accept_status = True)

    def login(self, request, context):
        '''
        å®¢æˆ·ç”³è¯·ç™»å½•
        request: usr_infoç±»å‹ä¿¡æ¯, å…¶ä¸­usr_IDå­—æ®µè‹¥ä¸º-1,åˆ™è¯´æ˜ä»æ¥ç™»å½•è¿‡, éœ€è¦ä¸ºå…¶åˆ†é…ä¸€ä¸ªID
        '''
        # 1. æŸ¥è¯·æ±‚ä¿¡æ¯, çœ‹æ˜¯å¦ç™»å½•è¿‡
        # 2. è‹¥æ²¡æœ‰ç™»å½•è¿‡, åˆ™ä¸ºå…¶åˆ†é…ä¸€ä¸ªID
        user_ID = request.usr_ID
        if user_ID == -1:
            #--------åŸå­æ“ä½œåŒº-------#
            with self.ID_Info_mtx:
                curMaxID = self.redisCli.get("max_usr_ID")
                user_ID = int(curMaxID) + 1
                self.redisCli.incr("max_usr_ID")
                self.redisCli.hset("usrlst", user_ID, request.usr_name)
            #------------------------#

        return DisServ_pb2.login_res(login_status = True, usr_ID = user_ID)

    
    def logout(self, request, context):
        '''
        å®¢æˆ·ç”³è¯·ç¦»çº¿(å®é™…å¹¶æ²¡æœ‰ä»€ä¹ˆç”¨å¤„, æ‰€ä»¥é—²ç½®äº†, ä»…åšäº†è±¡å¾æ€§çš„å®ç°)
        request: usr_infoç±»å‹ä¿¡æ¯
        '''
        # 1. å°†è¯¥ç”¨æˆ·ä»åœ¨çº¿ç”¨æˆ·åˆ—è¡¨ä¸­ç§»é™¤
        # 2. å³ä¾¿æ˜¯è¯¥ç”¨æˆ·å­˜åœ¨ç€å°šæœªå¬å›çš„å…±äº«æ–‡æ¡£, ä¹Ÿå…è®¸è¯¥ç”¨æˆ·ç¦»çº¿
        # 3. å°†è¯¥ç”¨æˆ·ç§»å…¥ç¦»çº¿ç”¨æˆ·åˆ—è¡¨, å¹¶å†™å…¥ç¦»çº¿æ—¶é—´(è‹¥è¶…è¿‡ä¸€å®šæ—¶é—´ä»æœªé‡æ–°ç™»å½•, åˆ™åˆ¤å®šä¸ºä¸æ´»è·ƒç”¨æˆ·)
        return DisServ_pb2.boolen_res(accept_status = True)
        
    
    def upload_document(self, request, context):
        '''
        request: documentç±»å‹ä¿¡æ¯
        '''
        # *å› ä¸ºæ™®é€šæ–‡æ¡£å¤§å°è¾ƒå°, è¿™é‡Œä¸ä½¿ç”¨æµå¼æœåŠ¡
        # *æ³¨æ„åœ¨ä¸Šä¼ æ–‡ä»¶çš„æ—¶å€™è¦åˆå§‹åŒ–è¡¥ä¸åˆ—è¡¨
        # 1. å…ˆåœ¨shareæ–‡ä»¶å¤¹ä¸‹æ–°å»ºä¸€ä¸ªæ–‡ä»¶, å‘½åæ ¼å¼ä¸º(ç”¨æˆ·ID-æ–‡ä»¶æè¿°ç¬¦-æ–‡ä»¶å)
        # 2. ä¹‹åæ¥æ”¶æ•°æ®, å°†æ•°æ®å†™å…¥æ–‡ä»¶, å†™å…¥å®Œæ¯•å, åˆå§‹åŒ–å¯¹åº”çš„è¡¥ä¸åˆ—è¡¨
        # 3. è¿”å›ç¡®è®¤


        # å…ˆæ£€æŸ¥æœ‰æ²¡æœ‰ä¸Šä¼ è¿‡åŒä¸€ä¸ªæ–‡ä»¶
        doc_info_serial = request.doc_info.SerializeToString()
        if self.redisCli.hexists("share_doc",doc_info_serial):
            # -åšæ£€æŸ¥, æŸ¥çœ‹æœ¬åœ°æ–‡ä»¶æ˜¯å¦è¿˜å­˜åœ¨, è‹¥ä¸å­˜åœ¨, å°±éœ€è¦æ¥æ”¶
            # -è‹¥å­˜åœ¨, å°±ç®—äº†
            return DisServ_pb2.boolen_res(accept_status = True)
        doc_info = request.doc_info
        doc_name = "-".join([str(doc_info.doc_ownerID), doc_info.doc_descriptor, doc_info.doc_name])
        doc_path = os.path.join(self.share_path, doc_name)
        
        with open(doc_path,"w",encoding="utf-8") as doc:
            doc.write('\n'.join(request.content))
        
        # æ–‡ä»¶å†™å…¥æˆåŠŸ, æ¥ä¸‹æ¥å¼€å§‹åŸå­æ“ä½œ:
        # 1. å…±äº«æ–‡æ¡£åˆ—è¡¨share_docæ·»åŠ è¯¥æ–°æ–‡ä»¶, æ—¶é—´æˆ³æ›´æ–°ä¸º0
        # 2. è®¿é—®max_patch_list_ID, ä¸ºå…¶åˆ†é…ä¸€ä¸ªpatchåˆ—è¡¨ID, ä¹‹åè¿›è¡Œè‡ªå¢
        # 3. åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ç±»å‹çš„é”®å€¼å¯¹patch-<ID>
        #-----------åŸå­æ“ä½œåŒº--------#
        # ä¼ å…¥share_docé”®, å°†å½“å‰æ–‡æ¡£info(åºåˆ—åŒ–)ä¼ å…¥
        # ä¼ å…¥max_patch_list_IDé”®, è·å–patch_ID
        # ä¼ å…¥doc_patché”®, å°†è·å–çš„patch_IDæ’å…¥(è¿™é‡Œåªè¦è·å–patch_IDå°±è¡Œ,å› ä¸ºç©ºåˆ—è¡¨æ˜¯æ— æ„ä¹‰çš„)
        # ä¼ å…¥dup_doc_veré”®, å¯¹å…¶è¿›è¡Œåˆå§‹åŒ–
        keys = ["share_doc","max_patch_list_ID", "doc_patch","dup_doc_ver"]
        args = [doc_info_serial]
        self.init_share_doc(keys=keys, args=args)
        #----------------------------#
        # å†æ£€æŸ¥ä¸€é, è‹¥æˆåŠŸå†™å…¥å°±è¿”å›æˆåŠŸ, è‹¥æ²¡æœ‰åˆ™è¿”å›é”™è¯¯
        if self.redisCli.hexists("share_doc", doc_info_serial):
            return DisServ_pb2.boolen_res(accept_status = True)
        else:
            return DisServ_pb2.boolen_res(accept_status = False)
    

    def recall_document(self, request, context):
        # TODO: ä¿®å¤ä¸‹é¢æåˆ°çš„bug
        #è¿™é‡Œæœ‰ç‚¹é—®é¢˜: åœ¨æ’¤å›æ–‡æ¡£ä¹‹å‰, åº”å½“ç¡®ä¿å°†æœ€æ–°ç‰ˆæœ¬çš„å‰¯æœ¬åŒæ­¥åˆ°æ–‡æ¡£æ‹¥æœ‰è€…, åœ¨æ­¤ä¹‹å‰, åº”å½“å°†æŸäº›é”®é”ä½#
        #è¿”å›çš„ç±»å‹åº”è¯¥æ›´æ”¹ä¸ºdocument
        '''
        request: document_infoç±»å‹ä¿¡æ¯
        '''
        # 1. å°†è¯¥æ–‡æ¡£æ–‡ä»¶ä»æœåŠ¡å™¨åˆ é™¤
        # 2. å°†æ–‡æ¡£ä¿¡æ¯ä»å…±äº«åˆ—è¡¨ä¸­ç§»é™¤
        # 3. å°†è¡¥ä¸åˆ—è¡¨åˆ é™¤å, å°†æ–‡æ¡£ä»doc_patchåˆ é™¤
        # 4. é€šçŸ¥å…¶ä»–ç”¨æˆ·, æˆ‘å·²ç»æ’¤å›äº†è¯¥æ–‡ä»¶, è¯¥æ–‡ä»¶ä¸å¯åœ¨çº¿ä¿®æ”¹(åœ¨åç»­è¯·æ±‚è¡¥ä¸çš„æ—¶å€™é€šçŸ¥)

        file_name = "-".join([str(request.doc_ownerID), request.doc_descriptor, request.doc_name])
        file_path = os.path.join(self.share_path, file_name)

        # è¿™é‡Œå¯èƒ½ä¼šæœ‰ç‚¹é—®é¢˜: å½“æœ‰å®¢æˆ·åœ¨è¯·æ±‚å½“å‰æ–‡æ¡£æ—¶, åˆ é™¤å¤±è´¥
        if os.path.exists(file_path):
            try:
                
                doc_info = request.SerializeToString()
                if not self.redisCli.hexists("share_doc", doc_info):
                    return DisServ_pb2.boolen_res(accept_status = False)

                # è¿™é‡Œä¸åšåŸå­æ“ä½œçš„è¯, æœ‰è„è¯»å–çš„é£é™©
                #---------åŸå­æ“ä½œåŒº---------#
                # ä¼ å…¥share_docé”®, ä¼ å…¥doc_info(åºåˆ—åŒ–), åˆ é™¤doc_info(åºåˆ—åŒ–)
                # ä¼ å…¥doc_patché”®, æ ¹æ®doc_infoè·å–å¯¹åº”çš„åˆ—è¡¨ID, åˆ é™¤åˆ—è¡¨åå†åˆ é™¤è¯¥åŸŸ
                # ä¼ å…¥dup_doc_veré”®, å¯¹å…¶è¿›è¡Œåˆ é™¤
                keys = ["share_doc", "doc_patch"]
                args = [doc_info]
                self.recall_doc(keys=keys, args=args)
                #---------------------------#
                os.remove(file_path)
                return DisServ_pb2.boolen_res(accept_status = True)
            except PermissionError:
                # åˆ é™¤å¤±è´¥, è¿”å›å¤±è´¥æ ‡è¯†
                return DisServ_pb2.boolen_res(accept_status = False)

    # è¿˜æ²¡debug
    def request_for_document(self, request, context):
        '''
        request: document_infoç±»å‹ä¿¡æ¯
        '''
        # 1. è¿™é‡Œé¦–å…ˆæ£€æŸ¥è¯·æ±‚æ–‡æ¡£è¿˜å­˜ä¸å­˜åœ¨(ç›´æ¥é€šè¿‡ç›¸å…³æ•°æ®æ‰¾ç›®å½•)
        # 2. å­˜åœ¨çš„è¯, å°†æ–‡æ¡£è¯»å…¥, è½¬åŒ–ä¸ºdocumentç±»å‹
        # 3. è¿™é‡Œçš„å¼‚å¸¸æƒ…å†µé‚£å¯å¤ªå¤šäº†, åæœŸæœ‰æ—¶é—´çš„æ—¶å€™åº”è¯¥å†è€ƒè™‘è€ƒè™‘
        file_name = "-".join([str(request.doc_ownerID), request.doc_descriptor, request.doc_name])
        file_path = os.path.join(self.share_path, file_name)
        if os.path.exists(file_path):
            try:
                file_content = []
                # ç­‰å¾…æ‰€æœ‰å°†è¡¥ä¸å†™å…¥çš„æ“ä½œå®Œæˆ
                with self.doc_mtx:
                    with open(file_path, "r", encoding="utf-8") as doc:
                        # è¿™é‡Œåœ¨è¯»æ–‡ä»¶æ—¶è‡ªåŠ¨å»æ‰æœ«å°¾æ‰€æœ‰ç©ºç™½å­—ç¬¦, åœ¨å®¢æˆ·ç«¯è¿›è¡Œdiffæ“ä½œæ—¶, ä¹Ÿåº”è¯¥éµå¾ªä¸€æ ·çš„åŸåˆ™
                        for line in doc:
                            file_content.append(line.rstrip())
                    
                    doc_info_serial = request.SerializeToString()
                    if self.redisCli.hexists("share_doc", doc_info_serial) and self.redisCli.hexists("dup_doc_ver", doc_info_serial):
                    # è¯´æ˜è¿˜æ²¡è¢«åˆ é™¤, èµ¶ç´§ä¼ è¾“
                        ts = self.redisCli.hget("dup_doc_ver", doc_info_serial)
                        return DisServ_pb2.document(doc_info = request, time_stamp = ts, content = file_content)
                        
            except PermissionError:
                pass
        # doc_info = DisServ_pb2.document_info(doc_name="NULL",doc_descriptor="NULL",doc_ownerID=-1)
        # æ—¶é—´æˆ³ä¸º-1è¯´æ˜è¯¥æ–‡ä»¶å·²ç»æ— äº†
        return DisServ_pb2.document(time_stamp=-1)
        
    
    # è¿˜æ²¡debug, æˆ–è€…è¯´, æ²¡deè¿‡çœŸçš„æœ‰ä¸Šä¼ patchçš„bug
    def request_for_patch(self, request, context):
        '''
        requestç±»å‹: patch
        '''
        # * éœ€è¦æ‰¾å‡ºå®¢æˆ·å½“å‰ç‰ˆæœ¬ä¸ç›®å‰æœ€æ–°ç‰ˆæœ¬ä¹‹é—´çš„æ‰€æœ‰è¡¥ä¸
        # * å³ä½¿äº§ç”Ÿæ±¡æŸ“è¯»çš„æƒ…å†µä¹Ÿæ²¡å…³ç³», å› ä¸ºåç»­å®¢æˆ·è¿˜ä¼šè¿›è¡Œè½®è¯¢, ä»¥ä¿æŒæ–‡æ¡£çš„ä¸€è‡´æ€§
        # * å¯èƒ½éœ€è¦åº”ä»˜åœ¨è¯·æ±‚è¡¥ä¸æ—¶, å‘ç”Ÿæ–‡ä»¶å˜åŠ¨(æ„å¤–ä¸¢å¤±æ–‡ä»¶æˆ–è€…æ–‡ä»¶è¢«æ’¤é”€å…±äº«)è€Œäº§ç”Ÿçš„å¼‚å¸¸

        # é¦–å…ˆä¸€å£æ°”è·å–æ‰€æœ‰patch
        ts = request.time_stamp
        doc_info = request.appli_doc.SerializeToString()
        #--åŸå­æ“ä½œ--(å¯èƒ½éœ€è¦å¦å†™ä¸€ä¸ªLuaè„šæœ¬ç¡®ä¿æ“ä½œåŸå­æ€§)
        patch_key = self.redisCli.hget("doc_patch", doc_info)
        patches = self.redisCli.lrange(patch_key,0,-1)


        # ä¹‹å, æ ¹æ®æ—¶é—´æˆ³çš„æ¡ä»¶, æµå¼åœ°å‘å¸ƒæ—¶é—´æˆ³è¶…å‰äºå®¢æˆ·ç‰ˆæœ¬çš„è¡¥ä¸
        #  ğŸ˜¢è¿™é‡Œéœ€è¦ä¿®æ”¹: è‹¥å½“å‰ç‰ˆæœ¬çš„ä¸‹ä¸€ä¸ªè¡¥ä¸æ²¡æœ‰å‡ºç°åœ¨è¡¥ä¸åˆ—è¡¨æ—¶, åˆ™è¿”å›ç›¸åº”çš„patchåšæé†’, ä½¿å®¢æˆ·ç«¯è‡ªä¸»è°ƒç”¨
        #     request_for_documentè·å–æœ€æ–°ç‰ˆæœ¬çš„å‰¯æœ¬

        is_continuous = False
        for patch_ in patches:
            patch = DisServ_pb2.patch()
            patch.ParseFromString(patch_)
            # åˆ¤æ–­æ˜¯å¦æœ‰è¡¥ä¸æ°å¥½æ˜¯å½“å‰ç‰ˆæœ¬çš„ä¸‹ä¸€ä¸ªç‰ˆæœ¬
            if patch.time_stamp == ts + 1:
                is_continuous = True
            # è‹¥å·²ç»å­˜åœ¨å½“å‰ç‰ˆæœ¬çš„ä¸‹ä¸€ä¸ªè¡¥ä¸, é‚£ä¹ˆå°†ä¹‹åçš„æ‰€æœ‰è¡¥ä¸éƒ½ä¸Šä¼ 
            if is_continuous and patch.time_stamp > ts:
                yield patch
            # å¦åˆ™, è¯´æ˜å½“å‰ç‰ˆæœ¬å¤ªè€äº†, è¿”å›ä¸€ä¸ªæ—¶é—´æˆ³ä¸º-1çš„ä¿¡æ¯, æé†’ç”¨æˆ·é‡æ–°è·å–å‰¯æœ¬
            elif patch.time_stamp > ts:
                yield DisServ_pb2.patch(time_stamp = -1)
                break
        
        return
    
    
    def request_for_sharelist(self, request, context):
        '''
        requestç±»å‹: è±¡å¾æ€§çš„boolen_res
        è¿”å›ç±»å‹: doc_list
        '''
        # ä¸€é”®è·å–å½“å‰share_docçš„æ‰€æœ‰é”®(list)
        fields = self.redisCli.hkeys("share_doc")
        doc_lst = []
        # æ‰“åŒ…æˆdoc_lstç±»å‹ä¿¡æ¯
        for item in fields:
            # è¿™é‡Œé¬¼æ‰“å¢™çº¯å±è‡ªå·±å‘è‡ªå·±, å› ä¸ºå¼•å…¥äº†ç©ºé”®' '
            if item.decode() != ' ':
                cur_info = DisServ_pb2.document_info()
                cur_info.ParseFromString(item)
                doc_lst.append(cur_info)
        return DisServ_pb2.doc_list(doc_info_list = doc_lst)

    def maintain_th(self):
        # æ¯éš”ä¸€æ®µæ—¶é—´å°±è°ƒç”¨ä¸€æ¬¡, å°½é‡ä½¿æ¯æ¬¡é—´éš”éƒ½ä¸ä¸€æ ·
        time_gaps = [0.3,0.9,2.1,0.9,1.1]
        gap_idx = 0
        while True:
            self.maintain_dup_doc()
            time.sleep(time_gaps[gap_idx])
            gap_idx += 1
            gap_idx %= len(time_gaps)



# TODO: å®ç°ä¸€ä¸ªçº¿ç¨‹, æ—¶åˆ»ç»´æŠ¤æœåŠ¡å™¨æ–‡ä»¶å‰¯æœ¬çš„ç‰ˆæœ¬, è¿™äº‹å®ä¸Šæ˜¯ä¸€ä¸ªæåº¦æ¶ˆè€—æ€§èƒ½çš„æ“ä½œ, åŒæ—¶ä¹Ÿä¼šä½¿æœåŠ¡å™¨çš„
#       åº”ç­”èƒ½åŠ›ä¸‹é™, å› ä¸ºäº’æ–¥æ­¤æ—¶æœåŠ¡å™¨æ— æ³•å¤„ç†ä¸Šä¼ æ–‡ä»¶çš„ä¸šåŠ¡
    def maintain_dup_doc(self):
        # 1. è·å–æ–‡ä»¶åˆ—è¡¨-->2. è·å–è¡¥ä¸åˆ—è¡¨-->3. è¿­ä»£å¼åœ°å†™å…¥

        doc_infos_serial = self.redisCli.hkeys("share_doc")
        # ä¸è·å–æ–‡ä»¶çš„æ“ä½œäº’æ–¥
        with self.doc_mtx:
            # å¯¹æ‰€æœ‰æ–‡ä»¶, éå†å…¶è¡¥ä¸åˆ—è¡¨
            for doc_info_serial in doc_infos_serial:
                if doc_info_serial.decode() != " ":
                    cur_ts = int(self.redisCli.hget("dup_doc_ver", doc_info_serial))
                    patchLstID = self.redisCli.hget("doc_patch",doc_info_serial)
                    patchLst_serial = self.redisCli.lrange(patchLstID, 0, -1)
                    # æ‰¹é‡è½¬æˆpatch

                    # è¿™é‡Œæœ‰å¾ˆå¤§çš„é—®é¢˜ï¼ï¼ï¼ï¼ï¼ ä½†æ˜¯å·²ç»åšäº†åˆæ­¥çš„ä¿®æ”¹
                    patchLst = []
                    for patch in patchLst_serial:
                        single_patch = DisServ_pb2.patch()
                        single_patch.ParseFromString(patch)
                        patchLst.append(single_patch)
                    
                    try:
                        gap = patchLst[-1].time_stamp - cur_ts
                        # æ»¡è¶³é˜ˆå€¼æ¡ä»¶, å¼€å§‹å†™å…¥
                        if gap > self.threshold:
                            doc_info = DisServ_pb2.document_info().ParseFromString(doc_info_serial)
                            file_path = os.path.join(self.share_path, 
                                                    "-".join(str(doc_info.doc_ownerID), doc_info.doc_descriptor, doc_info.doc_name))
                            
                            if os.path.exists(file_path):
                                # è‹¥æ–‡ä»¶å­˜åœ¨, å¼€å§‹è¿›è¡Œè¡¥ä¸çš„å†™å…¥
                                raw_file = []
                                with open(file_path, "r", encoding="utf-8") as file:
                                    raw_file.append(line.rstrip() for line in file)
                                for i in range(len(patchLst)-gap, len(patchLst)):
                                    raw_file = apply_patch_cover(patchLst[i], raw_file)
                                with open(file_path, "w", encoding="utf-8") as file:
                                    file.write('\n'.join(raw_file))
                                self.redisCli.hset("dup_doc_ver", doc_info_serial, patchLst[-1].time_stamp)

                                # å¼€å§‹ç»´æŠ¤è¡¥ä¸åˆ—è¡¨çš„æ•°é‡
                                if len(patchLst) > self.k:
                                    self.redisCli.ltrim(patchLstID, -self.k, -1) 
                            else:
                                # TODO: ç­‰å¾…å®ç°é”™è¯¯æç¤º, ä»¥åŠæ–‡ä»¶æ¢å¤çš„æ“ä½œ(åç»­æœ‰æ—¶é—´å†åš)
                                # æ–‡ä»¶æ¢å¤çš„æ“ä½œåº”è¯¥ç•™åœ¨è¯·æ±‚è¡¥ä¸å¤„, ä¹‹åé€šè¿‡æŸç§æœºåˆ¶, ç¡®ä¿åªæœ‰ä¸€ä¸ªç”¨æˆ·å‘é€å‰¯æœ¬
                                pass
                    except IndexError:
                        # è¯´æ˜é€»è¾‘é”™è¯¯äº†, åŸå­æ“ä½œå¤±æ•ˆ, è¡¥ä¸åˆ—è¡¨å·²ç»æ¸…ç©º, ä½†æ–‡æ¡£ä¿¡æ¯è¿˜åœ¨
                        pass



if __name__ == "__main__":
    ServerHandel = server()
    Server = grpc.server(futures.ThreadPoolExecutor(max_workers=16))
    SerPort = ServerHandel.serPort
    DisServ_pb2_grpc.add_DisServServicer_to_server( ServerHandel,Server)
    Server.add_insecure_port('[::]:'+str(SerPort))
    Server.start()
    Server.wait_for_termination()
    pass